{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "z9RkSUHZk6uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Questions"
      ],
      "metadata": {
        "id": "O0GtEIIYk2mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "  - A parameter is a model configuration internal to the algorithm, learned from the training data (e.g., coefficients in linear regression or weights in neural networks).\n",
        "\n",
        "2. What is correlation?  What does negative correlation mean?\n",
        "  - Correlation measures the linear relationship between two variables, ranging from -1 to 1.\n",
        "\n",
        "  - Negative correlation means that as one variable increases, the other variable tends to decrease. The relationship moves in opposite directions. For example, as the price of a product increases, the demand for it typically decreases, showing a negative correlation.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine Learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed for every task.\n",
        "\n",
        "  - Main components:\n",
        "  - Dataset\n",
        "  - Model/Algorithm\n",
        "  - Features\n",
        "  - Loss function\n",
        "  - Optimizer\n",
        "  - Evaluation metrics\n",
        "\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - Loss value measures how far the model's predictions are from the actual values. A lower loss indicates better model performance:\n",
        "\n",
        "    - High loss = poor model performance (large prediction errors)\n",
        "    - Low loss = good model performance (small prediction errors)\n",
        "    - Loss helps in comparing different models and tracking improvement during training.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "  - Continuous variables: Numerical values that can take any value within a range (e.g., height, temperature, salary)\n",
        "  - Categorical variables: Variables that represent discrete categories or groups (e.g., gender, color, brand names)\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Techniques:\n",
        "\n",
        "  - Label Encoding\n",
        "\n",
        "  - One-Hot Encoding\n",
        "\n",
        "  - Ordinal Encoding\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "  - Training: Using a portion of data to teach the model patterns and relationships\n",
        "  - Testing: Using a separate portion of data to evaluate how well the model performs on unseen data\n",
        "   - This split helps assess if the model can generalize to new data rather than just memorizing the training data.       \n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "  - Sklearn.preprocessing is a module in scikit-learn that provides tools for data preprocessing, including:\n",
        "\n",
        "    - Feature scaling (StandardScaler, MinMaxScaler)\n",
        "    - Encoding categorical variables (LabelEncoder, OneHotEncoder)\n",
        "    - Data transformation and normalization\n",
        "    - Handling missing data\n",
        "\n",
        "9. What is a Test set?\n",
        "  - A test set is a portion of data (typically 20-30%) that is kept separate from training and used only for final model evaluation. It provides an unbiased assessment of model performance on completely unseen data\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "  - Using `train_test_split()` from `sklearn.model_selection`.\n",
        "        ```\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "        ```  \n",
        "  -  Define problem\n",
        "\n",
        "  - Collect & clean data\n",
        "\n",
        "  - EDA (Explore Data)\n",
        "\n",
        "  - Feature Engineering\n",
        "\n",
        "  - Train/Test split\n",
        "\n",
        "  - Model selection\n",
        "\n",
        "  - Train the model\n",
        "\n",
        "  - Evaluate and improve\n",
        "\n",
        "11.  Why do we have to perform EDA before fitting a model to the data?\n",
        "  - EDA helps to:\n",
        "\n",
        "  - Understand data distribution and quality\n",
        "  - Identify missing values and outliers\n",
        "  - Discover patterns and relationships\n",
        "  - Select relevant features\n",
        "  - Choose appropriate preprocessing techniques\n",
        "  - Identify potential data issues early\n",
        "  - Make informed decisions about model selection\n",
        "\n",
        "12. What is correlation?\n",
        "  - Correlation measures the linear relationship between two variables, ranging from -1 to 1.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "  -  Negative correlation means that as one variable increases, the other variable tends to decrease. The relationship moves in opposite directions. For example, as the price of a product increases, the demand for it typically decreases, showing a negative correlation.  \n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "  -\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Using pandas\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Using numpy\n",
        "correlation = np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "# Using scipy\n",
        "from scipy.stats import pearsonr\n",
        "correlation, p_value = pearsonr(x, y)\n",
        "\n",
        "#Using heatmap\n",
        "df.corr()   \n",
        "sns.heatmap(df.corr(), annot=True)  # Seaborn heatmap\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means one variable directly causes changes in another variable.\n",
        "Difference:\n",
        "\n",
        "  - Correlation: Statistical relationship between variables\n",
        "  - Causation: One variable actually causes changes in another\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer is an algorithm that adjusts model parameters to minimize the loss function.\n",
        "  - Types:\n",
        "\n",
        "    - SGD (Stochastic Gradient Descent): Updates parameters using gradients from single samples\n",
        "    - Adam: Adaptive learning rate optimizer combining momentum and RMSprop\n",
        "    - RMSprop: Adapts learning rate based on recent gradients\n",
        "    - Adagrad: Adapts learning rate based on historical gradients\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "  - sklearn.linear_model is a module containing linear models for regression and classification:\n",
        "\n",
        "    - LinearRegression\n",
        "    - LogisticRegression\n",
        "    - Ridge, Lasso regression\n",
        "    - ElasticNet     \n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "  - model.fit() trains the model on training data. Required arguments:\n",
        "\n",
        "  - X: Training features (input data)\n",
        "  - y: Training targets (output data)\n",
        "\n",
        "        ```\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        ```\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "  - model.predict() makes predictions on new data. Required argument:\n",
        "\n",
        "  - X: Features for prediction\n",
        "\n",
        "  ```\n",
        "  model.predict(X_test)\n",
        "\n",
        "  ```\n",
        "20. What are continuous and categorical variables?\n",
        "  -   Continuous variables: Numerical values that can take any value within a range (e.g., height, temperature, salary)\n",
        "  - Categorical variables: Variables that represent discrete categories or groups (e.g., gender, color, brand names)\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling is a data preprocessing technique that transforms the numerical features of a dataset to a similar scale.\n",
        "  - This helps prevent features with larger values from disproportionately influencing the model, leading to improved performance and faster convergence, especially in algorithms sensitive to feature magnitudes.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "  -\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "```  \n",
        "23. What is sklearn.preprocessing?\n",
        "  -  Sklearn.preprocessing is a module in scikit-learn that provides tools for data preprocessing, including:\n",
        "\n",
        "    - Feature scaling (StandardScaler, MinMaxScaler)\n",
        "    - Encoding categorical variables (LabelEncoder, OneHotEncoder)\n",
        "    - Data transformation and normalization\n",
        "    - Handling missing data\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "  -  Using `train_test_split()` from `sklearn.model_selection`.\n",
        "        ```\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "        ```  \n",
        "\n",
        "\n",
        "25. Explain data encoding?\n",
        "  - Converting categorical variables to numeric form.\n",
        "\n",
        "  - Methods:\n",
        "\n",
        "    - Label Encoding: Integer labels\n",
        "\n",
        "    - One-Hot Encoding: Binary columns\n",
        "\n",
        "    - Ordinal Encoding: Ranked categories              "
      ],
      "metadata": {
        "id": "5JnPMOxZlD0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzfjEDuzkxOk"
      },
      "outputs": [],
      "source": []
    }
  ]
}